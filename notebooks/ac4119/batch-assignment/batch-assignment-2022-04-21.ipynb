{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch 3 (2022-04-21)\n",
    "An issue was detected where the intial batch appeared to use a different version of `randomized_example_ids.p` This batch (and part of the subsequent batch) will rectify this by prioiritizing the example_ids that should have already been assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yj2369_labelling_assignment_2022-04-13.csv', 'gm2858_labelling_assignment_2022-04-09.csv', 'yp2201_labelling_assignment_2022-04-09.csv', 'ac4119_labelling_assignment_2022-04-09.csv', 'ac4119_labelling_assignment_2022-04-13.csv', 'yp2201_labelling_assignment_2022-04-13.csv', 'gm2858_labelling_assignment_2022-04-13.csv', 'yj2369_labelling_assignment_2022-04-09.csv']\n",
      "/Users/ameliachu/repos/nlu-reddit-toxicity-dataset/data/randomized_example_ids.p\n"
     ]
    }
   ],
   "source": [
    "repo_dir = \"/Users/ameliachu/repos/nlu-reddit-toxicity-dataset\"\n",
    "labelled_data_dir = f\"{repo_dir}/data/labelled/\"\n",
    "\n",
    "# Collecting all the labelled file names \n",
    "labelled_data_fnames = [f for f in os.listdir(labelled_data_dir)]\n",
    "\n",
    "# Pre-randomized list of example_ids\n",
    "randomized_example_ids_path = f\"{repo_dir}/data/randomized_example_ids.p\"\n",
    "\n",
    "# Dictionary of example_ids that have been labelled once\n",
    "# See assign-examples-for-interrater.ipynb for more details\n",
    "interrater_assignment_path = f\"{repo_dir}/data/interrater-reliability/interrater_assignment_2022-04-21.p\"\n",
    "\n",
    "print(labelled_data_fnames)\n",
    "print(randomized_example_ids_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading pickles to inform example assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_indices = pickle.load( open(randomized_example_ids_path, \"rb\" ) )\n",
    "interrater_assignment = pickle.load( open(interrater_assignment_path, \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the example_ids that should have labelled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtaining a full list of all the example_ids that have currently been labelled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['example_id']\n",
    "list_of_example_ids = [pd.read_csv(f\"{labelled_data_dir}{fname}\")[selected_columns] for fname in labelled_data_fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_example_ids.append(pd.read_csv(f\"{repo_dir}/data/to_label/yp2201_labelling_assignment_2022-04-13\")[selected_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_ids_pd = pd.concat(list_of_example_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1361, 1358)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(example_ids_pd), example_ids_pd.nunique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_that_should_have_labels = example_indices[:1360]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_label_immediately = set(ids_that_should_have_labels) - set(example_ids_pd.example_id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "597"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_label_immediately)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabbing the index of each example_id we are missing, so that we can replace the example_ids \n",
    "in the correct order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_to_replace = [example_indices.index(i) for i in to_label_immediately]\n",
    "ordered_indices = list(set(indices_to_replace))\n",
    "missing_example_ids = [example_indices[i] for i in ordered_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[375030, 200577, 329502, 511720, 52314]\n"
     ]
    }
   ],
   "source": [
    "print(missing_example_ids[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining  raters who need to be assigned a batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rater_ids = ['ac4119', 'gm2858', 'yj2369','yp2201']\n",
    "num_raters = len(rater_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the starting index, and the number of examples to include per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_id = 0\n",
    "batch_size = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "supplmental_batches = []\n",
    "\n",
    "for i in range(num_raters):\n",
    "    end_id = start_id + batch_size\n",
    "    supplmental_batches.append((start_id, end_id))\n",
    "    start_id = end_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 140), (140, 280), (280, 420), (420, 560)]\n"
     ]
    }
   ],
   "source": [
    "print(supplmental_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomizing the order of raters and assigning batches based on order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(rater_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ac4119', (0, 140)), ('yj2369', (140, 280)), ('yp2201', (280, 420)), ('gm2858', (420, 560))]\n"
     ]
    }
   ],
   "source": [
    "assign_batches_to_raters =  list(zip(rater_ids,supplmental_batches))\n",
    "print(assign_batches_to_raters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving to pickle the remaining example_ids that require backfilling for the next batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_examples_to_backfill = missing_example_ids[560:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(remaining_examples_to_backfill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_backfill_path = f'{repo_dir}/data/backfill_example_ids.p'\n",
    "# pickle.dump(remaining_examples_to_backfill, open(remaining_backfill_path, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in pre-collected dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_discussion_data_fname = \"daily_master_data_1614250838_1618692612.csv\"\n",
    "daily_discussion_data_path = f\"{repo_dir}/data/{daily_discussion_data_fname}\"\n",
    "daily_discussion_data = pd.read_csv(daily_discussion_data_path).rename(columns={'Unnamed: 0':'example_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating files for labelling based on batch assignment\n",
    "\n",
    "This chunk uses the `rater_id` and assigned indices `(start_ind, end_ind)` as inputs. The process collects the relevant data and generates a file that is more conducive to labelling and text classification training/scoring. Specifically, the below collects the context (i.e. `preceding_comment`, `following_comment`), the `comment_for_evaluation`, and adds columns for each toxic attribute label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_label_dir = f\"{repo_dir}/data/to_label\"\n",
    "current_date = dt.date.today()\n",
    "labels = ['toxicity', 'severe_toxicity', 'identity_attack', 'insult', 'profanity', 'threat']\n",
    "\n",
    "for rater_id, (start_ind, end_ind) in assign_batches_to_raters:\n",
    "    fname = f\"{rater_id}_labelling_assignment_{current_date}\"\n",
    "    export_location = f\"{to_label_dir}/{fname}\"\n",
    "    assigned_indices = missing_example_ids[start_ind:end_ind]\n",
    "    assigned_indices += interrater_assignment[rater_id]\n",
    "    index_map = {}\n",
    "    required_examples = []\n",
    "    for ind in assigned_indices:\n",
    "        ind_examples = [{\n",
    "        'example_id': str(ind),\n",
    "        'example_type': 'preceding',\n",
    "        'body': daily_discussion_data[daily_discussion_data['example_id'] == ind-1]['body'].values[0]\n",
    "    }, {\n",
    "        'example_id': str(ind),\n",
    "        'example_type': 'example',\n",
    "        'body': daily_discussion_data[daily_discussion_data['example_id'] == ind]['body'].values[0]\n",
    "    },\n",
    "     {\n",
    "        'example_id': str(ind),\n",
    "        'example_type': 'following',\n",
    "        'body': daily_discussion_data[daily_discussion_data['example_id'] == ind+1]['body'].values[0]\n",
    "    }]\n",
    "        required_examples += ind_examples \n",
    "    assigned_data = pd.DataFrame(required_examples)\n",
    "    # Adding in the primary example info and the type of example for each row.\n",
    "    assigned_data = assigned_data[['example_type','example_id','body']].reset_index()\n",
    "    assigned_examples_pivot = assigned_data.pivot(index='example_id', columns='example_type', values='body').reset_index()[['example_id','preceding', 'example','following']]\n",
    "    assigned_examples = assigned_examples_pivot.rename(columns={\n",
    "         'preceding':'preceding_comment',\n",
    "         'following':'following_comment',\n",
    "         'example':'comment_for_evaluation'})\n",
    "    for label in labels:\n",
    "         assigned_examples[label] = \"\"\n",
    "    assigned_examples.to_csv(export_location, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(assigned_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
