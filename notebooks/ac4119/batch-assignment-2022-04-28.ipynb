{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch 4 (2022-04-28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"/Users/ameliachu/repos/nlu-reddit-toxicity-dataset\"\n",
    "labelled_data_dir = f\"{repo_dir}/data/labelled/\"\n",
    "\n",
    "# Collecting all the labelled file names \n",
    "labelled_data_fnames = [f for f in os.listdir(labelled_data_dir)]\n",
    "\n",
    "# Pre-randomized list of example_ids\n",
    "randomized_example_ids_path = f\"{repo_dir}/data/randomized_example_ids.p\"\n",
    "\n",
    "# example_ids that require backfill due to init assigment issue\n",
    "remaining_backfill_path = f'{repo_dir}/data/backfill_example_ids.p'\n",
    "\n",
    "# Dictionary of example_ids that have been labelled once\n",
    "# See assign-examples-for-interrater.ipynb for more details\n",
    "interrater_assignment_date = '2022-04-28' \n",
    "interrater_assignment_path = f\"{repo_dir}/data/interrater-reliability/interrater_assignment_{interrater_assignment_date}.p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_examples_to_backfill = pickle.load( open(remaining_backfill_path, \"rb\" ) )\n",
    "example_indices = pickle.load( open(randomized_example_ids_path, \"rb\" ) )\n",
    "interrater_assignment = pickle.load( open(interrater_assignment_path, \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtaining a list of labelled examples\n",
    "\n",
    "selected_columns = ['example_id']\n",
    "list_of_example_ids = [pd.read_csv(f\"{labelled_data_dir}{fname}\")[selected_columns] for fname in labelled_data_fnames]\n",
    "example_ids_pd = pd.concat(list_of_example_ids)\n",
    "labelled_examples = list(example_ids_pd['example_id'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining raters who need to be assigned a batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rater_ids = ['ac4119', 'gm2858', 'yj2369','yp2201']\n",
    "num_raters = len(rater_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_id = 1360\n",
    "batch_size = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_example_indices = example_indices[start_id:]\n",
    "current_example_indices = [i for i in current_example_indices if i not in labelled_examples ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "supplmental_batches = []\n",
    "\n",
    "for i in range(num_raters):\n",
    "    if i == 0:\n",
    "        start_id = 0\n",
    "        n_backfill = len(remaining_examples_to_backfill)\n",
    "        end_id = start_id + batch_size - n_backfill\n",
    "    else:\n",
    "        end_id = start_id + batch_size\n",
    "    supplmental_batches.append((start_id,end_id))\n",
    "    start_id = end_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supplmental_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomizing the order of raters and assigning batches based on order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(rater_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('yp2201', (0, 103)), ('ac4119', (103, 243)), ('yj2369', (243, 383)), ('gm2858', (383, 523))]\n"
     ]
    }
   ],
   "source": [
    "assign_batches_to_raters =  list(zip(rater_ids,supplmental_batches))\n",
    "print(assign_batches_to_raters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in pre-collected dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_discussion_data_fname = \"daily_master_data_1614250838_1618692612.csv\"\n",
    "daily_discussion_data_path = f\"{repo_dir}/data/{daily_discussion_data_fname}\"\n",
    "daily_discussion_data = pd.read_csv(daily_discussion_data_path).rename(columns={'Unnamed: 0':'example_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating files for labelling based on batch assignment\n",
    "\n",
    "This chunk uses the `rater_id` and assigned indices `(start_ind, end_ind)` as inputs. The process collects the relevant data and generates a file that is more conducive to labelling and text classification training/scoring. Specifically, the below collects the context (i.e. `preceding_comment`, `following_comment`), the `comment_for_evaluation`, and adds columns for each toxic attribute label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_label_dir = f\"{repo_dir}/data/to_label\"\n",
    "current_date = dt.date.today()\n",
    "labels = ['toxicity', 'severe_toxicity', 'identity_attack', 'insult', 'profanity', 'threat']\n",
    "\n",
    "for rater_id, (start_ind, end_ind) in assign_batches_to_raters:\n",
    "    fname = f\"{rater_id}_labelling_assignment_{current_date}\"\n",
    "    export_location = f\"{to_label_dir}/{fname}\"\n",
    "    assigned_indices = current_example_indices[start_ind:end_ind]\n",
    "    if start_id == 0:\n",
    "        assigned_indices += remaining_examples_to_backfill\n",
    "    assigned_indices += interrater_assignment[rater_id]\n",
    "    index_map = {}\n",
    "    required_examples = []\n",
    "    for ind in assigned_indices:\n",
    "        ind_examples = [{\n",
    "        'example_id': str(ind),\n",
    "        'example_type': 'preceding',\n",
    "        'body': daily_discussion_data[daily_discussion_data['example_id'] == ind-1]['body'].values[0]\n",
    "    }, {\n",
    "        'example_id': str(ind),\n",
    "        'example_type': 'example',\n",
    "        'body': daily_discussion_data[daily_discussion_data['example_id'] == ind]['body'].values[0]\n",
    "    },\n",
    "     {\n",
    "        'example_id': str(ind),\n",
    "        'example_type': 'following',\n",
    "        'body': daily_discussion_data[daily_discussion_data['example_id'] == ind+1]['body'].values[0]\n",
    "    }]\n",
    "        required_examples += ind_examples \n",
    "    assigned_data = pd.DataFrame(required_examples)\n",
    "    # Adding in the primary example info and the type of example for each row.\n",
    "    assigned_data = assigned_data[['example_type','example_id','body']].reset_index()\n",
    "    assigned_examples_pivot = assigned_data.pivot(index='example_id', columns='example_type', values='body').reset_index()[['example_id','preceding', 'example','following']]\n",
    "    assigned_examples = assigned_examples_pivot.rename(columns={\n",
    "         'preceding':'preceding_comment',\n",
    "         'following':'following_comment',\n",
    "         'example':'comment_for_evaluation'})\n",
    "    for label in labels:\n",
    "         assigned_examples[label] = \"\"\n",
    "    assigned_examples.to_csv(export_location, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 103)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_discussion_data[daily_discussion_data['example_id'] == ind-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 103),\n",
       " (103, 243),\n",
       " (243, 383),\n",
       " (383, 523),\n",
       " 290885,\n",
       " 615643,\n",
       " 86008,\n",
       " 170161,\n",
       " 122521,\n",
       " 295359,\n",
       " 448991,\n",
       " 346447,\n",
       " 558444,\n",
       " 370363,\n",
       " 110661,\n",
       " 348478,\n",
       " 276444,\n",
       " 75306,\n",
       " 54650,\n",
       " 65805,\n",
       " 374145,\n",
       " 597705,\n",
       " 202461,\n",
       " 588864,\n",
       " 455576,\n",
       " 296815,\n",
       " 16915,\n",
       " 179361,\n",
       " 417611,\n",
       " 142273,\n",
       " 46107,\n",
       " 416841,\n",
       " 368880,\n",
       " 24710,\n",
       " 427008,\n",
       " 501180,\n",
       " 595771,\n",
       " 2072,\n",
       " 535474,\n",
       " 457356,\n",
       " 465073,\n",
       " 413921,\n",
       " 86632,\n",
       " 378037,\n",
       " 554332,\n",
       " 538144,\n",
       " 395243,\n",
       " 13786,\n",
       " 82485,\n",
       " 534685,\n",
       " 23154,\n",
       " 193771,\n",
       " 511720,\n",
       " 480746,\n",
       " 326880,\n",
       " 128832,\n",
       " 568475,\n",
       " 413686,\n",
       " 265978,\n",
       " 537192,\n",
       " 31882,\n",
       " 277373,\n",
       " 70825,\n",
       " 25974,\n",
       " 38381,\n",
       " 346470,\n",
       " 269192,\n",
       " 591880,\n",
       " 504766,\n",
       " 32952,\n",
       " 529495,\n",
       " 424081,\n",
       " 609573,\n",
       " 94141,\n",
       " 512007,\n",
       " 52314,\n",
       " 285378,\n",
       " 554146,\n",
       " 566377,\n",
       " 98356,\n",
       " 182906,\n",
       " 379993,\n",
       " 398290,\n",
       " 618295,\n",
       " 350511,\n",
       " 547861,\n",
       " 71377,\n",
       " 192843,\n",
       " 280313,\n",
       " 99989,\n",
       " 153292,\n",
       " 41179,\n",
       " 367275,\n",
       " 105125,\n",
       " 400560,\n",
       " 601750,\n",
       " 522826,\n",
       " 495207,\n",
       " 197535,\n",
       " 449552,\n",
       " 152642,\n",
       " 332182,\n",
       " 453418,\n",
       " 340637,\n",
       " 551996,\n",
       " 172999,\n",
       " 88000,\n",
       " 583256,\n",
       " 524532,\n",
       " 327299,\n",
       " 78350,\n",
       " 206977,\n",
       " 9162,\n",
       " 314139,\n",
       " 83108,\n",
       " 473177,\n",
       " 533008,\n",
       " 26260,\n",
       " 21451,\n",
       " 593942,\n",
       " 287659,\n",
       " 192642,\n",
       " 235312,\n",
       " 482417,\n",
       " 238392,\n",
       " 595015,\n",
       " 7529,\n",
       " 263930,\n",
       " 499263,\n",
       " 432464,\n",
       " 603849,\n",
       " 327480,\n",
       " 318080,\n",
       " 418198,\n",
       " 528806,\n",
       " 325826,\n",
       " 349343,\n",
       " 57966,\n",
       " 57332,\n",
       " 521270,\n",
       " 510265,\n",
       " 503616,\n",
       " 130620,\n",
       " 182043,\n",
       " 586265,\n",
       " 271240,\n",
       " 132708,\n",
       " 317782,\n",
       " 31896,\n",
       " 604388,\n",
       " 275897,\n",
       " 209260,\n",
       " 298642,\n",
       " 6359,\n",
       " 285316,\n",
       " 524157,\n",
       " 148739,\n",
       " 509358,\n",
       " 211361,\n",
       " 255861,\n",
       " 197597]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
