| Toxic Attribute  | Definition |
| ----------- | ----------- |
| toxicity    | A rude, disrespectful, or unreasonable comment that is likely to make people leave a discussion.      |
| severe_toxicity    | A very hateful, aggressive, disrespectful comment or otherwise very likely to make a user leave a discussion or give up on sharing their perspective. This attribute is much less sensitive to more mild forms of toxicity, such as comments that include positive uses of curse words.      |
| identity_attack   | Negative or hateful comments targeting someone because of their identity*.<br>Identity is any protected class (e.g. race, ethnicity, religion, sex (including pregnancy, sexual orientation, or gender identity), national origin, age (40 or older), disability and genetic information).     |
| insult    | Insulting, inflammatory, or negative comment towards a person or a group of people.       |
| profanity   |  Swear words, curse words, or other obscene or profane language.       |



### Additional Guidelines

- in WSB, a declarative statement, doesn’t necessarily shut down dialogue.
- We will only try to discern intent from the comment_for_evaluation and the context (i.e. preceding, following). If there comment appears to qualify for one of the the attributes and there is nothing explicit which suggest otherwise (e.g. sarcasm, non-intent-of-harm )

**toxicity**

It’s more likely to be toxic when:

1. It’s directed toward an individual.
2. If I read that comment, I would would feel sad or upset
3. Err on the side of toxicity, but still profanity != toxicity
4. Not likely to lead to productive discussion

**profanity**

- any acronyms of profanity = profanity

**identity_attack**

- an identity mention (e.g. non-hateful slur) does not equate to an identity attack
- Given that the comment is negative or hateful, if the word (by general consensus e.g. quick google search) is a “slur”, then it’s an identity_attack, if it is considered as just “vulgar”, it is not an identity attack.
