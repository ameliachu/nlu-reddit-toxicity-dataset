{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Initial Batch of 200 Examples to Label\n",
    "\n",
    "In this notebook, we generate a randomized list of example_ids from the pre-collected dataset (`daily_master_data_1614250838_1618692612.csv`). This randomized list will be used to assign raters batchs of data to label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"/Users/ameliachu/repos/nlu-reddit-toxicity-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining output directory/paths\n",
    "randomized_example_ids_path = f\"{repo_dir}/data/randomized_example_ids.p\"\n",
    "to_label_dir = f\"{repo_dir}/data/to_label\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_discussion_data_fname = \"daily_master_data_1614250838_1618692612.csv\"\n",
    "daily_discussion_data_path = f\"{repo_dir}/data/{daily_discussion_data_fname}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in pre-collected dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_discussion_data = pd.read_csv(daily_discussion_data_path).rename(columns={'Unnamed: 0':'example_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>sub_id</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ls42x6</td>\n",
       "      <td>1.614251e+09</td>\n",
       "      <td>first</td>\n",
       "      <td>7</td>\n",
       "      <td>I_make_switch_a_roos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ls42x6</td>\n",
       "      <td>1.614251e+09</td>\n",
       "      <td>Rise and shine bitches</td>\n",
       "      <td>41</td>\n",
       "      <td>LitenVarg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ls42x6</td>\n",
       "      <td>1.614251e+09</td>\n",
       "      <td>Here we go. 🚀</td>\n",
       "      <td>14</td>\n",
       "      <td>readingtostrangers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ls42x6</td>\n",
       "      <td>1.614251e+09</td>\n",
       "      <td>GME to 420.69 EOD</td>\n",
       "      <td>14</td>\n",
       "      <td>wottsraja</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ls42x6</td>\n",
       "      <td>1.614251e+09</td>\n",
       "      <td>Second retard</td>\n",
       "      <td>2</td>\n",
       "      <td>AceSouth</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   example_id  sub_id   created_utc                    body  score  \\\n",
       "0           0  ls42x6  1.614251e+09                   first      7   \n",
       "1           1  ls42x6  1.614251e+09  Rise and shine bitches     41   \n",
       "2           2  ls42x6  1.614251e+09           Here we go. 🚀     14   \n",
       "3           3  ls42x6  1.614251e+09       GME to 420.69 EOD     14   \n",
       "4           4  ls42x6  1.614251e+09           Second retard      2   \n",
       "\n",
       "                 author  \n",
       "0  I_make_switch_a_roos  \n",
       "1             LitenVarg  \n",
       "2    readingtostrangers  \n",
       "3             wottsraja  \n",
       "4              AceSouth  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_discussion_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Examples: 619,646; Number of Example Ids: 619,646\n"
     ]
    }
   ],
   "source": [
    "num_examples = len(daily_discussion_data)\n",
    "num_dst_example_ids = daily_discussion_data['example_id'].nunique()\n",
    "print(f\"Number of Examples: {num_examples:,}; Number of Example Ids: {num_dst_example_ids:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting the `example_id`s and randomizing order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "example_indices = list(daily_discussion_data['example_id'].values)\n",
    "print(example_indices[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[494030, 420324, 473177, 419306, 506755]\n"
     ]
    }
   ],
   "source": [
    "random.seed(519)\n",
    "random.shuffle(example_indices)\n",
    "print(example_indices[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(example_indices, open(randomized_example_ids_path , \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomly assigning the intial batch (n=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the randomized `example_id` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_indices = pickle.load( open(randomized_example_ids_path, \"rb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining  raters who need to be assigned a batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rater_ids = ['ac4119', 'gm2858', 'yj2369','yp2201']\n",
    "num_raters = len(rater_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the starting index, and the number of examples to include per batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_id = 0 \n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 200), (200, 400), (400, 600), (600, 800)]\n"
     ]
    }
   ],
   "source": [
    "init_batches = []\n",
    "\n",
    "for i in range(num_raters):\n",
    "    end_id = start_id + batch_size\n",
    "    init_batches.append((start_id,end_id))\n",
    "    start_id = end_id\n",
    "\n",
    "print(init_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomizing the order of raters and assigning batches based on order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(rater_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_batches_to_raters = list(zip(rater_ids,init_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('gm2858', (0, 200)),\n",
       " ('yp2201', (200, 400)),\n",
       " ('yj2369', (400, 600)),\n",
       " ('ac4119', (600, 800))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assign_batches_to_raters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating files for labelling based on batch assignment\n",
    "\n",
    "This chunk uses the `rater_id` and assigned indices `(start_ind, end_ind)` as inputs. The process collects the relevant data and generates a file that is more conducive to labelling and text classification training/scoring. Specifically, the below collects the context (i.e. `preceding_comment`, `following_comment`), the `comment_for_evaluation`, and adds columns for each toxic attribute label.\n",
    "\n",
    "*Note*: an issue was detected with this chunk after assigning the intial batch. This methodology, does not allow for same comments to appear in the same file (e.g. a comment that is both a `preceding_comment` and a `comment_for_evaluation`). This was rectified in subsequent batch assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7920825113d2>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned_data ['example_type'] = assigned_data .apply(lambda x: index_map.get(x['example_id'], {}).get(\"type\"), axis=1)\n",
      "<ipython-input-27-7920825113d2>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned_data ['example_id'] = assigned_data .apply(lambda x: index_map.get(x['example_id'], {}).get(\"example_id\"), axis=1)\n",
      "<ipython-input-27-7920825113d2>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned_data ['example_type'] = assigned_data .apply(lambda x: index_map.get(x['example_id'], {}).get(\"type\"), axis=1)\n",
      "<ipython-input-27-7920825113d2>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned_data ['example_id'] = assigned_data .apply(lambda x: index_map.get(x['example_id'], {}).get(\"example_id\"), axis=1)\n",
      "<ipython-input-27-7920825113d2>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned_data ['example_type'] = assigned_data .apply(lambda x: index_map.get(x['example_id'], {}).get(\"type\"), axis=1)\n",
      "<ipython-input-27-7920825113d2>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned_data ['example_id'] = assigned_data .apply(lambda x: index_map.get(x['example_id'], {}).get(\"example_id\"), axis=1)\n",
      "<ipython-input-27-7920825113d2>:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned_data ['example_type'] = assigned_data .apply(lambda x: index_map.get(x['example_id'], {}).get(\"type\"), axis=1)\n",
      "<ipython-input-27-7920825113d2>:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  assigned_data ['example_id'] = assigned_data .apply(lambda x: index_map.get(x['example_id'], {}).get(\"example_id\"), axis=1)\n"
     ]
    }
   ],
   "source": [
    "current_date = dt.date.today()\n",
    "labels = ['toxicity', 'severe_toxicity', 'identity_attack', 'insult', 'profanity', 'threat']\n",
    "\n",
    "for rater_id, (start_ind, end_ind) in assign_batches_to_raters:\n",
    "    # init export file names\n",
    "    fname = f\"{rater_id}_labelling_assignment_{current_date}\"\n",
    "    export_location = f\"{to_label_dir}/{fname}\"\n",
    "    # determining which example_ids are the comment_for_evaluation\n",
    "    assigned_indices = example_indices[start_ind:end_ind]\n",
    "    index_map = {}\n",
    "    required_indices = []\n",
    "    # Collecting the context for each comment_for_evaluation\n",
    "    for ind in assigned_indices:\n",
    "        index_map[ind-1] = {\n",
    "        'example_id': str(ind),\n",
    "        'type': 'preceding'\n",
    "    }\n",
    "        index_map[ind] = {\n",
    "        'example_id': str(ind),\n",
    "        'type': 'example'\n",
    "    }\n",
    "        index_map[ind+1] = {\n",
    "        'example_id': str(ind),\n",
    "        'type': 'following'\n",
    "    }\n",
    "        required_indices += [ind-1,ind, ind+1]\n",
    "    # collecting all the example_ids needed for this batch \n",
    "    # (i.e. context & comment_for_evaluation)\n",
    "    assigned_data = daily_discussion_data.iloc[required_indices]\n",
    "    \n",
    "    # Adding in the primary example info and the type of example for each row.\n",
    "    assigned_data ['example_type'] = assigned_data .apply(lambda x: index_map.get(x['example_id'], {}).get(\"type\"), axis=1)\n",
    "    assigned_data ['example_id'] = assigned_data .apply(lambda x: index_map.get(x['example_id'], {}).get(\"example_id\"), axis=1)\n",
    "    assigned_data = assigned_data[['example_type','example_id','body']]\n",
    "    \n",
    "    # Pivoting the dataframe so that each example_type is its own column\n",
    "    assigned_examples_pivot = assigned_data.pivot(index='example_id', columns='example_type', values='body').reset_index()[['example_id','preceding', 'example','following']]\n",
    "    assigned_examples = assigned_examples_pivot.rename(columns={\n",
    "         'preceding':'preceding_comment',\n",
    "         'following':'following_comment',\n",
    "         'example':'comment_for_evaluation'})\n",
    "    \n",
    "    # Adding in columns for each toxic attribute label\n",
    "    for label in labels:\n",
    "         assigned_examples[label] = \"\"\n",
    "    # Write out file\n",
    "    assigned_examples.to_csv(export_location, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verifying Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assigned_data_example = pd.read_csv(export_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>preceding_comment</th>\n",
       "      <th>comment_for_evaluation</th>\n",
       "      <th>following_comment</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>profanity</th>\n",
       "      <th>threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105580</td>\n",
       "      <td>I'm shorting JPOW</td>\n",
       "      <td>It's going back up</td>\n",
       "      <td>I got into so many good spacs today 🦘</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106714</td>\n",
       "      <td>Were going to need to change the banner at the...</td>\n",
       "      <td>I wish all the fucking leaf blowers would come...</td>\n",
       "      <td>Waiting to load up on NASDAQ CFDs at around 12...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>107332</td>\n",
       "      <td>Lol, this is still correction territory.\\n\\nWa...</td>\n",
       "      <td>I fucking hope not</td>\n",
       "      <td>JAY FIRE THE PRINTERS! JAY?! JAYYYYYYYY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11714</td>\n",
       "      <td>I did 2 years ago all cards went like times 10</td>\n",
       "      <td>All these fucks have paper hands</td>\n",
       "      <td>AMC!!!!!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>117374</td>\n",
       "      <td>Yeah wtf do you think “I was close” means?</td>\n",
       "      <td>I like sugar with my margaritas. Not salt.</td>\n",
       "      <td>I like alts on top of alts. And boy did I get it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   example_id                                  preceding_comment  \\\n",
       "0      105580                                  I'm shorting JPOW   \n",
       "1      106714  Were going to need to change the banner at the...   \n",
       "2      107332  Lol, this is still correction territory.\\n\\nWa...   \n",
       "3       11714     I did 2 years ago all cards went like times 10   \n",
       "4      117374         Yeah wtf do you think “I was close” means?   \n",
       "\n",
       "                              comment_for_evaluation  \\\n",
       "0                                 It's going back up   \n",
       "1  I wish all the fucking leaf blowers would come...   \n",
       "2                                 I fucking hope not   \n",
       "3                   All these fucks have paper hands   \n",
       "4         I like sugar with my margaritas. Not salt.   \n",
       "\n",
       "                                   following_comment  toxicity  \\\n",
       "0              I got into so many good spacs today 🦘       NaN   \n",
       "1  Waiting to load up on NASDAQ CFDs at around 12...       NaN   \n",
       "2            JAY FIRE THE PRINTERS! JAY?! JAYYYYYYYY       NaN   \n",
       "3                                          AMC!!!!!!       NaN   \n",
       "4   I like alts on top of alts. And boy did I get it       NaN   \n",
       "\n",
       "   severe_toxicity  identity_attack  insult  profanity  threat  \n",
       "0              NaN              NaN     NaN        NaN     NaN  \n",
       "1              NaN              NaN     NaN        NaN     NaN  \n",
       "2              NaN              NaN     NaN        NaN     NaN  \n",
       "3              NaN              NaN     NaN        NaN     NaN  \n",
       "4              NaN              NaN     NaN        NaN     NaN  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assigned_data_example.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
