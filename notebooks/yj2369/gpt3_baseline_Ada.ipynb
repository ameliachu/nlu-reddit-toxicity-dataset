{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db55de26",
   "metadata": {},
   "source": [
    "## GPT-3 Ada\n",
    "\n",
    "### Description:\n",
    "- This notebook is using GPT-3 API to classify label results.\n",
    "- This model uses data from r/wallstreetbets, and focuses on 6 labels\n",
    "- labels(6): TOXICITY, SEVERE_TOXICITY, IDENTITY_ATTACK, INSULT, PROFANITY, THREAT\n",
    "- GPT-3 can be found at https://beta.openai.com/\n",
    "\n",
    "### Version:\n",
    "#### - ver 0.1.0(220418): \n",
    "- baseline results for only current comments\n",
    "- classifies 800 comments from r/wallstreetbets\n",
    "\n",
    "#### - ver ///(TBD): \n",
    "- results for current comments, but using preceding/following comments as reference\n",
    "- using fine-tuning methods such as: ///\n",
    "- classifies 800 + @ comments from r/wallstreetbets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68b3a097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you've installed openai. If not, uncomment below line and install openai.\n",
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70edc96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of dataset: (800, 10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>example_id</th>\n",
       "      <th>preceding_comment</th>\n",
       "      <th>comment_for_evaluation</th>\n",
       "      <th>following_comment</th>\n",
       "      <th>toxicity</th>\n",
       "      <th>severe_toxicity</th>\n",
       "      <th>identity_attack</th>\n",
       "      <th>insult</th>\n",
       "      <th>profanity</th>\n",
       "      <th>threat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104857</td>\n",
       "      <td>[https://www.youtube.com/watch?v=hRBOnA0ak4w&amp;a...</td>\n",
       "      <td>GME just watching this all and doing nothing lol</td>\n",
       "      <td>[https://www.youtube.com/watch?v=hRBOnA0ak4w&amp;a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>105125</td>\n",
       "      <td>#GOTTA GET THAT 1.48% ON A BOND WHOOOO</td>\n",
       "      <td>Everything is down today, knee jerk reaction t...</td>\n",
       "      <td>AMC, I held all this time and I decided to buy...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>105684</td>\n",
       "      <td>Having 30k to lose sounds pretty nice to me</td>\n",
       "      <td>No, this is the Warthog</td>\n",
       "      <td>a good trump tweet would turn all this carnage...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105904</td>\n",
       "      <td>His tools for inflation are literally rates an...</td>\n",
       "      <td>The market is not worth what you guys have bee...</td>\n",
       "      <td>Can somebody make clear that it's not us who a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1138</td>\n",
       "      <td>Wot?</td>\n",
       "      <td>Didnt he sell all his shares?</td>\n",
       "      <td>This is the way lol holding 100 March 12 / $51...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   example_id                                  preceding_comment  \\\n",
       "0      104857  [https://www.youtube.com/watch?v=hRBOnA0ak4w&a...   \n",
       "1      105125             #GOTTA GET THAT 1.48% ON A BOND WHOOOO   \n",
       "2      105684        Having 30k to lose sounds pretty nice to me   \n",
       "3      105904  His tools for inflation are literally rates an...   \n",
       "4        1138                                               Wot?   \n",
       "\n",
       "                              comment_for_evaluation  \\\n",
       "0   GME just watching this all and doing nothing lol   \n",
       "1  Everything is down today, knee jerk reaction t...   \n",
       "2                            No, this is the Warthog   \n",
       "3  The market is not worth what you guys have bee...   \n",
       "4                      Didnt he sell all his shares?   \n",
       "\n",
       "                                   following_comment  toxicity  \\\n",
       "0  [https://www.youtube.com/watch?v=hRBOnA0ak4w&a...         0   \n",
       "1  AMC, I held all this time and I decided to buy...         0   \n",
       "2  a good trump tweet would turn all this carnage...         0   \n",
       "3  Can somebody make clear that it's not us who a...         0   \n",
       "4  This is the way lol holding 100 March 12 / $51...         0   \n",
       "\n",
       "   severe_toxicity  identity_attack  insult  profanity  threat  \n",
       "0                0                0       0          0       0  \n",
       "1                0                0       0          0       0  \n",
       "2                0                0       0          0       0  \n",
       "3                0                0       0          0       0  \n",
       "4                0                0       0          0       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# should change file directory to given csv file's path\n",
    "data = pd.read_csv('labelled_master_data_2022-04-18.csv')\n",
    "print('shape of dataset:', data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3cf4db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 10 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   example_id              800 non-null    int64 \n",
      " 1   preceding_comment       800 non-null    object\n",
      " 2   comment_for_evaluation  800 non-null    object\n",
      " 3   following_comment       800 non-null    object\n",
      " 4   toxicity                800 non-null    int64 \n",
      " 5   severe_toxicity         800 non-null    int64 \n",
      " 6   identity_attack         800 non-null    int64 \n",
      " 7   insult                  800 non-null    int64 \n",
      " 8   profanity               800 non-null    int64 \n",
      " 9   threat                  800 non-null    int64 \n",
      "dtypes: int64(7), object(3)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f03b6b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_for_eval = data['comment_for_evaluation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "974b6158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining prompt\n",
    "# prompt = instruction + label + definition + comment + result\n",
    "# instruction/label/definition/result is stable, while comment is changed\n",
    "instruction = 'instructions:\\n\\\n",
    "Please evaluate comment for evaluation on the labels provided. You can refer to the definitions of each labels below. Answer as format \" , , , , , \".\\n\\n'\n",
    "\n",
    "label = 'labels provided:\\n\\\n",
    "TOXICITY, SEVERE_TOXICITY, IDENTITY_ATTACK, INSULT, PROFANITY, THREAT\\n\\n\\\n",
    "label values:\\n\\\n",
    "1 - Matches the Definition\\n\\\n",
    "0 - Does not match the Definition\\n\\n'\n",
    "\n",
    "definition = 'definitions of each labels:\\n\\\n",
    "TOXICITY: A rude, disrespectful, or unreasonable comment that is likely to make people leave a discussion.\\n\\\n",
    "SEVERE_TOXICITY: A very hateful, aggressive, disrespectful comment or otherwise very likely to make a user leave a discussion or give up on sharing their perspective. This attribute is much less sensitive to more mild forms of toxicity, such as comments that include positive uses of curse words.\\n\\\n",
    "IDENTITY_ATTACK: Negative or hateful comments targeting someone because of their identity.\\n\\\n",
    "INSULT: Insulting, inflammatory, or negative comment towards a person or a group of people.\\n\\\n",
    "PROFANITY: Swear words, curse words, or other obscene or profane language.\\n\\\n",
    "THREAT: Describes an intention to inflict pain, injury, or violence against an individual or group.\\n\\n'\n",
    "\n",
    "result = 'result:\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f74c84a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "# replace with your api_key (should start with 'sh-///', https://beta.openai.com/account/api-keys)\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Checking with Ada\n",
    "# replace your prompt\n",
    "# below parameters are used for baseline result\n",
    "\n",
    "res = []\n",
    "\n",
    "for each_comment in comments_for_eval.values:\n",
    "    comment_full_sentence = 'comment for evaluation:\\n' + each_comment + '\\n\\n'\n",
    "    prompt_wsb = instruction + label + definition + comment_full_sentence + result\n",
    "    \n",
    "    response = openai.Completion.create(\n",
    "      engine=\"text-ada-001\",\n",
    "      prompt=prompt_wsb,\n",
    "      temperature=0,\n",
    "      max_tokens=60,\n",
    "      top_p=1.0,\n",
    "      frequency_penalty=0.0,\n",
    "      presence_penalty=0.0\n",
    "    )\n",
    "    \n",
    "    res.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a9be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt3_toxic, gpt3_sev_toxic, gpt3_identity, gpt3_insult, gpt3_profanity, gpt3_threat = [], [], [] ,[], [], []\n",
    "\n",
    "for each_res in range(len(res)):\n",
    "    toxic_res = int(res[each_res]['choices'][0]['text'].split(', ')[0])\n",
    "    sev_toxic_res = int(res[each_res]['choices'][0]['text'].split(', ')[1])\n",
    "    identity_res = int(res[each_res]['choices'][0]['text'].split(', ')[2])\n",
    "    insult_res = int(res[each_res]['choices'][0]['text'].split(', ')[3])\n",
    "    profanity_res = int(res[each_res]['choices'][0]['text'].split(', ')[4])\n",
    "    threat_res = int(res[each_res]['choices'][0]['text'].split(', ')[5])\n",
    "                                                                                                                                                                                                                             \n",
    "    gpt3_toxic.append(toxic_res)\n",
    "    gpt3_sev_toxic.append(sev_toxic_res)\n",
    "    gpt3_identity.append(identity_res)\n",
    "    gpt3_insult.append(insult_res)\n",
    "    gpt3_profanity.append(profanity_res)\n",
    "    gpt3_threat.append(threat_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fac5e49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adding results into dataframe, by defining new columns\n",
    "\n",
    "data['gpt3_toxic'] = gpt3_toxic\n",
    "data['gpt3_sev_toxic'] = gpt3_sev_toxic\n",
    "data['gpt3_identity'] = gpt3_identity\n",
    "data['gpt3_insult'] = gpt3_insult\n",
    "data['gpt3_profanity'] = gpt3_profanity\n",
    "data['gpt3_threat'] = gpt3_threat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37809f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./result_ada.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e8aa10",
   "metadata": {},
   "source": [
    "## Evaluation of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00b35b3",
   "metadata": {},
   "source": [
    "### Now given all labels using gpt-3, compare gpt-3 with human labeling\n",
    "<b>- Results:  \n",
    "total) f1: 0.51, precision: 0.40, recall: 0.69</b>  \n",
    "toxicity) f1: 0.16, precision: 1.00, recall: 0.09  \n",
    "severe_toxicity) f1: 0.33, precision: 0.33, recall: 0.33  \n",
    "identity_attack) f1: 0.20, precision: 1.00, recall: 0.11  \n",
    "insult) f1: 0.44, precision: 0.33, recall: 0.67  \n",
    "profanity) f1: 0.59, precision: 0.44, recall: 0.87  \n",
    "threat) f1: NaN, precision: 0, recall: NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b5d460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_precision_recall(y_true, y_pred): \n",
    "    \n",
    "    # recall that f1 score = 2 * (precision * recall) / (precision + recall)\n",
    "    # precision = tp / (tp + fp)\n",
    "    # recall = tp / (tp + fn)\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    precision, recall = 0, 0\n",
    "    \n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == 1 and y_pred[i] == 1: tp += 1\n",
    "        elif y_true[i] == 0 and y_pred[i] == 0: tn += 1\n",
    "        elif y_true[i] == 0 and y_pred[i] == 1: fp += 1\n",
    "        elif y_true[i] == 1 and y_pred[i] == 0: fn += 1            \n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "\n",
    "    f1 = 2 * (precision * recall) / (precision + recall)\n",
    "    \n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b74b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will get f1, precision, recall, respectively\n",
    "toxic_f1, toxic_precision, toxic_recall = f1_precision_recall(data['toxicity'], data['gpt3_toxic'])\n",
    "sev_f1, sev_precision, sev_recall = f1_precision_recall(data['severe_toxicity'], data['gpt3_sev_toxic'])\n",
    "idn_f1, idn_precision, idn_recall = f1_precision_recall(data['identity_attack'], data['gpt3_identity'])\n",
    "insult_f1, insult_precision, insult_recall = f1_precision_recall(data['insult'], data['gpt3_insult'])\n",
    "prof_f1, prof_precision, prof_recall = f1_precision_recall(data['profanity'], data['gpt3_profanity'])\n",
    "# threat_f1, threat_precision, threat_recall = f1_precision_recall(data['threat'], data['gpt3_threat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f07cfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: we can't calculate threat as threat_recall = 0/0. threat_precision = 0/8 = 0.0 (0 792 8 0)\n",
    "\n",
    "print('toxicity) f1: {:.2f}, precision: {:.2f}, recall: {:.2f}'.format(toxic_f1, toxic_precision, toxic_recall))\n",
    "print('severe_toxicity) f1: {:.2f}, precision: {:.2f}, recall: {:.2f}'.format(sev_f1, sev_precision, sev_recall))\n",
    "print('identity_attack) f1: {:.2f}, precision: {:.2f}, recall: {:.2f}'.format(idn_f1, idn_precision, idn_recall))\n",
    "print('insult) f1: {:.2f}, precision: {:.2f}, recall: {:.2f}'.format(insult_f1, insult_precision, insult_recall))\n",
    "print('profanity) f1: {:.2f}, precision: {:.2f}, recall: {:.2f}'.format(prof_f1, prof_precision, prof_recall))\n",
    "# print('threat) f1:{:.2f}, precision:{:.2f}, recall:{:.2f}'.format(threat_f1, threat_precision, threat_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e00a44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calcuating total(but can also average the results as rows for each results are even)\n",
    "y_true_total = pd.concat([data['toxicity'], data['severe_toxicity'], data['identity_attack'], data['insult'], \\\n",
    "                          data['profanity'], data['threat']], axis=0)\n",
    "\n",
    "y_pred_total = pd.concat([data['gpt3_toxic'], data['gpt3_sev_toxic'], data['gpt3_identity'], data['gpt3_insult'], \\\n",
    "                          data['gpt3_profanity'], data['gpt3_threat']], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bbf9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_f1, total_precision, total_recall = f1_precision_recall(list(y_true_total), list(y_pred_total))\n",
    "print('total) f1: {:.2f}, precision: {:.2f}, recall: {:.2f}'.format(total_f1, total_precision, total_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e1037e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
