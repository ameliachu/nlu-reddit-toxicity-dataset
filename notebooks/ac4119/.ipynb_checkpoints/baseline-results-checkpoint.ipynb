{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"/Users/ameliachu/repos/nlu-reddit-toxicity-dataset\"\n",
    "results_dir = f\"{repo_dir}/artifacts/results\"\n",
    "date = '2022-05-11'\n",
    "\n",
    "master_data_location  = f\"{repo_dir}/data/labelled_master_data_{date}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['severe_toxicity', 'toxicity', 'identity_attack', 'insult', 'profanity', 'threat']\n",
    "\n",
    "truth_labels = {label : f'y_truth_{label}' for label in labels}\n",
    "pred_labels = {label : f'y_pred_{label}' for label in labels}\n",
    "\n",
    "selected_columns = ['example_id'] + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sets = {\n",
    "    'Human': {\n",
    "        \"file_name\": \"baseline_human-1_2022-05-07.csv\",\n",
    "    },\n",
    "#     'human_2': {\n",
    "#         \"file_name\": \"baseline_human-2_2022-05-07.csv\",\n",
    "#     },\n",
    "    'BERT': {\n",
    "        \"file_name\": \"baseline_bert_5_11.csv\",\n",
    "    },\n",
    "    'DeBERTa v3': {\n",
    "        \"file_name\": \"baseline_deberta_5_11.csv\",\n",
    "    },\n",
    "    'RoBERTa': {\n",
    "        \"file_name\": \"baseline_roberta_5_11.csv\",\n",
    "    },\n",
    "    'GPT-3 (One-Shot)': {\n",
    "        \"file_name\": \"baseline_gpt3_2022-05-12.csv\",\n",
    "    },\n",
    "    'GPT-3 (Few-Shot)': {\n",
    "        \"file_name\": \"baseline_GPT-3_FewShot_2022_5_11.csv\",\n",
    "    },\n",
    "    \n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in pred_sets:\n",
    "    file_location = f\"{results_dir}/{pred_sets[model]['file_name']}\"\n",
    "    pred_sets[model][\"df\"] = pd.read_csv( file_location) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_set = pd.read_csv(master_data_location)\n",
    "truth_set = truth_set[selected_columns]\n",
    "\n",
    "overall_truth_set = pd.melt(truth_set, id_vars = ['example_id'], value_vars=labels).rename(columns={'value':'y_truth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "for model in pred_sets:\n",
    "    model_results = pred_sets[model][\"df\"]\n",
    "    \n",
    "    test_set_ids = list(model_results['example_id'].values)\n",
    "    model_truth_set = truth_set[truth_set['example_id'].isin(test_set_ids)]\n",
    "    model_truth_set_renamed = model_truth_set.rename(columns=truth_labels)\n",
    "    \n",
    "    model_preds = model_results[selected_columns]\n",
    "    model_preds_renamed = model_results.rename(columns=pred_labels)\n",
    "    overall_model_preds = pd.melt(model_results, id_vars = ['example_id'], value_vars=labels).rename(columns={'value':'y_pred'})\n",
    "    \n",
    "    y_labels = model_truth_set_renamed.merge(model_preds_renamed, on='example_id')\n",
    "    overall_y_labels = overall_truth_set.merge(overall_model_preds, on='example_id')\n",
    "    \n",
    "    precision, recall, f1_score, support = precision_recall_fscore_support(\n",
    "        overall_y_labels['y_truth'], overall_y_labels['y_pred'], \n",
    "        labels=[0.0,1.0], beta=1, zero_division=0)\n",
    "    eval_results = {\n",
    "            'model': model,\n",
    "            'attribute': 'overall',\n",
    "            'precision': precision[1],\n",
    "            'recall': recall[1],\n",
    "            'f1_score': f1_score[1],\n",
    "            'count':len(overall_y_labels['y_truth'])\n",
    "        }\n",
    "    \n",
    "    results_list.append(eval_results)\n",
    "    for label in labels:\n",
    "        y_truth_label = f'y_truth_{label}'\n",
    "        y_pred_label = f'y_pred_{label}'\n",
    "        precision, recall, f1_score, support = precision_recall_fscore_support(y_labels[y_truth_label].values, y_labels[y_pred_label].values,\n",
    "                                                                               labels=[0.0,1.0], beta=1, zero_division=0)\n",
    "\n",
    "        eval_results = {\n",
    "            'model': model,\n",
    "            'attribute': label,\n",
    "            'precision': precision[1],\n",
    "            'recall': recall[1],\n",
    "            'f1_score': f1_score[1],\n",
    "            'count':len(overall_y_labels['y_truth'])\n",
    "        }\n",
    "\n",
    "        results_list.append(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_results = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_melt = pd.melt(full_model_results, id_vars=['model','attribute'], value_vars=['precision','f1_score','recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below should be the Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results_table = pd.pivot_table(\n",
    "    model_results_melt, \n",
    "         values=['value'],\n",
    "         index=['variable','attribute'],\n",
    "         columns='model'\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results_table.columns = ['Metric','Attribute','BERT','DeBERTa v3','GPT-3 (Few-Shot)','GPT-3 (One-Shot)','Human','RoBERTa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results_table = baseline_results_table[['metric','attribute','Human','BERT','RoBERTa','DeBERTa v3','GPT-3 (One-Shot)','GPT-3 (Few-Shot)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_results_table.to_csv(f'{repo_dir}/reporting/assets/baseline-results.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>attribute</th>\n",
       "      <th>Human</th>\n",
       "      <th>BERT</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>DeBERTa v3</th>\n",
       "      <th>GPT-3 (One-Shot)</th>\n",
       "      <th>GPT-3 (Few-Shot)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>identity_attack</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>insult</td>\n",
       "      <td>0.686869</td>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.343891</td>\n",
       "      <td>0.480211</td>\n",
       "      <td>0.458472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>overall</td>\n",
       "      <td>0.480370</td>\n",
       "      <td>0.270904</td>\n",
       "      <td>0.265495</td>\n",
       "      <td>0.258457</td>\n",
       "      <td>0.264572</td>\n",
       "      <td>0.249668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>profanity</td>\n",
       "      <td>0.882883</td>\n",
       "      <td>0.788774</td>\n",
       "      <td>0.793558</td>\n",
       "      <td>0.793558</td>\n",
       "      <td>0.827014</td>\n",
       "      <td>0.513562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>severe_toxicity</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>threat</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>f1_score</td>\n",
       "      <td>toxicity</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.344371</td>\n",
       "      <td>0.309795</td>\n",
       "      <td>0.290749</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.388060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>precision</td>\n",
       "      <td>identity_attack</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.720000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>precision</td>\n",
       "      <td>insult</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.417582</td>\n",
       "      <td>0.365462</td>\n",
       "      <td>0.403509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>precision</td>\n",
       "      <td>overall</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.264957</td>\n",
       "      <td>0.258108</td>\n",
       "      <td>0.266758</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>precision</td>\n",
       "      <td>profanity</td>\n",
       "      <td>0.890909</td>\n",
       "      <td>0.981618</td>\n",
       "      <td>0.974820</td>\n",
       "      <td>0.974820</td>\n",
       "      <td>0.794989</td>\n",
       "      <td>0.959459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>precision</td>\n",
       "      <td>severe_toxicity</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>precision</td>\n",
       "      <td>threat</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>precision</td>\n",
       "      <td>toxicity</td>\n",
       "      <td>0.575758</td>\n",
       "      <td>0.226744</td>\n",
       "      <td>0.206061</td>\n",
       "      <td>0.191304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.327044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>recall</td>\n",
       "      <td>identity_attack</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.268657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>recall</td>\n",
       "      <td>insult</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.530769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>recall</td>\n",
       "      <td>overall</td>\n",
       "      <td>0.574586</td>\n",
       "      <td>0.271454</td>\n",
       "      <td>0.266034</td>\n",
       "      <td>0.258808</td>\n",
       "      <td>0.262421</td>\n",
       "      <td>0.212285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>recall</td>\n",
       "      <td>profanity</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.659259</td>\n",
       "      <td>0.669136</td>\n",
       "      <td>0.669136</td>\n",
       "      <td>0.861728</td>\n",
       "      <td>0.350617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>recall</td>\n",
       "      <td>severe_toxicity</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>recall</td>\n",
       "      <td>threat</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>recall</td>\n",
       "      <td>toxicity</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.605505</td>\n",
       "      <td>0.036697</td>\n",
       "      <td>0.477064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       metric        attribute     Human      BERT   RoBERTa  DeBERTa v3  \\\n",
       "0    f1_score  identity_attack  0.500000  0.085714  0.111111    0.080000   \n",
       "1    f1_score           insult  0.686869  0.403226  0.421875    0.343891   \n",
       "2    f1_score          overall  0.480370  0.270904  0.265495    0.258457   \n",
       "3    f1_score        profanity  0.882883  0.788774  0.793558    0.793558   \n",
       "4    f1_score  severe_toxicity  0.375000  0.074074  0.000000    0.097561   \n",
       "5    f1_score           threat  0.666667  0.000000  0.400000    0.000000   \n",
       "6    f1_score         toxicity  0.703704  0.344371  0.309795    0.290749   \n",
       "7   precision  identity_attack  0.372093  1.000000  0.800000    0.375000   \n",
       "8   precision           insult  0.641509  0.423729  0.428571    0.417582   \n",
       "9   precision          overall  0.412698  0.270355  0.264957    0.258108   \n",
       "10  precision        profanity  0.890909  0.981618  0.974820    0.974820   \n",
       "11  precision  severe_toxicity  0.272727  0.333333  0.000000    0.117647   \n",
       "12  precision           threat  0.500000  0.000000  0.500000    0.000000   \n",
       "13  precision         toxicity  0.575758  0.226744  0.206061    0.191304   \n",
       "14     recall  identity_attack  0.761905  0.044776  0.059701    0.044776   \n",
       "15     recall           insult  0.739130  0.384615  0.415385    0.292308   \n",
       "16     recall          overall  0.574586  0.271454  0.266034    0.258808   \n",
       "17     recall        profanity  0.875000  0.659259  0.669136    0.669136   \n",
       "18     recall  severe_toxicity  0.600000  0.041667  0.000000    0.083333   \n",
       "19     recall           threat  1.000000  0.000000  0.333333    0.000000   \n",
       "20     recall         toxicity  0.904762  0.715596  0.623853    0.605505   \n",
       "\n",
       "    GPT-3 (One-Shot)  GPT-3 (Few-Shot)  \n",
       "0           0.160000          0.391304  \n",
       "1           0.480211          0.458472  \n",
       "2           0.264572          0.249668  \n",
       "3           0.827014          0.513562  \n",
       "4           0.388889          0.181818  \n",
       "5           0.117647          0.250000  \n",
       "6           0.070796          0.388060  \n",
       "7           0.750000          0.720000  \n",
       "8           0.365462          0.403509  \n",
       "9           0.266758          0.303030  \n",
       "10          0.794989          0.959459  \n",
       "11          0.583333          0.333333  \n",
       "12          0.071429          0.200000  \n",
       "13          1.000000          0.327044  \n",
       "14          0.089552          0.268657  \n",
       "15          0.700000          0.530769  \n",
       "16          0.262421          0.212285  \n",
       "17          0.861728          0.350617  \n",
       "18          0.291667          0.125000  \n",
       "19          0.333333          0.333333  \n",
       "20          0.036697          0.477064  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
