{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_dir = \"/Users/ameliachu/repos/nlu-reddit-toxicity-dataset\"\n",
    "results_dir = f\"{repo_dir}/artifacts/results\"\n",
    "date = '2022-05-11'\n",
    "\n",
    "master_data_location  = f\"{repo_dir}/data/labelled_master_data_{date}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['severe_toxicity', 'toxicity', 'identity_attack', 'insult', 'profanity', 'threat']\n",
    "\n",
    "truth_labels = {label : f'y_truth_{label}' for label in labels}\n",
    "pred_labels = {label : f'y_pred_{label}' for label in labels}\n",
    "\n",
    "selected_columns = ['example_id'] + labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sets = {\n",
    "    'human': {\n",
    "        \"file_name\": \"baseline_human-1_2022-05-07.csv\",\n",
    "    },\n",
    "#     'human_2': {\n",
    "#         \"file_name\": \"baseline_human-2_2022-05-07.csv\",\n",
    "#     },\n",
    "    'BERT': {\n",
    "        \"file_name\": \"baseline_bert_5_11.csv\",\n",
    "    },\n",
    "    'DeBERTa v3': {\n",
    "        \"file_name\": \"baseline_deberta_5_11.csv\",\n",
    "    },\n",
    "    'RoBERTa': {\n",
    "        \"file_name\": \"baseline_roberta_5_11.csv\",\n",
    "    },\n",
    "    'GPT-3': {\n",
    "        \"file_name\": \"baseline_gpt3_2022-05-12.csv\",\n",
    "    },\n",
    "    \n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in pred_sets:\n",
    "    file_location = f\"{results_dir}/{pred_sets[model]['file_name']}\"\n",
    "    pred_sets[model][\"df\"] = pd.read_csv( file_location) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_set = pd.read_csv(master_data_location)\n",
    "truth_set = truth_set[selected_columns]\n",
    "\n",
    "overall_truth_set = pd.melt(truth_set, id_vars = ['example_id'], value_vars=labels).rename(columns={'value':'y_truth'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_list = []\n",
    "for model in pred_sets:\n",
    "    model_results = pred_sets[model][\"df\"]\n",
    "    \n",
    "    test_set_ids = list(model_results['example_id'].values)\n",
    "    model_truth_set = truth_set[truth_set['example_id'].isin(test_set_ids)]\n",
    "    model_truth_set_renamed = model_truth_set.rename(columns=truth_labels)\n",
    "    \n",
    "    model_preds = model_results[selected_columns]\n",
    "    model_preds_renamed = model_results.rename(columns=pred_labels)\n",
    "    overall_model_preds = pd.melt(model_results, id_vars = ['example_id'], value_vars=labels).rename(columns={'value':'y_pred'})\n",
    "    \n",
    "    y_labels = model_truth_set_renamed.merge(model_preds_renamed, on='example_id')\n",
    "    overall_y_labels = overall_truth_set.merge(overall_model_preds, on='example_id')\n",
    "    \n",
    "    precision, recall, f1_score, support = precision_recall_fscore_support(\n",
    "        overall_y_labels['y_truth'], overall_y_labels['y_pred'], \n",
    "        labels=[0.0,1.0], beta=1, zero_division=0)\n",
    "    eval_results = {\n",
    "            'model': model,\n",
    "            'attribute': 'overall',\n",
    "            'precision': precision[1],\n",
    "            'recall': recall[1],\n",
    "            'f1_score': f1_score[1],\n",
    "            'count':len(overall_y_labels['y_truth'])\n",
    "        }\n",
    "    \n",
    "    results_list.append(eval_results)\n",
    "    for label in labels:\n",
    "        y_truth_label = f'y_truth_{label}'\n",
    "        y_pred_label = f'y_pred_{label}'\n",
    "        precision, recall, f1_score, support = precision_recall_fscore_support(y_labels[y_truth_label].values, y_labels[y_pred_label].values,\n",
    "                                                                               labels=[0.0,1.0], beta=1, zero_division=0)\n",
    "\n",
    "        eval_results = {\n",
    "            'model': model,\n",
    "            'attribute': label,\n",
    "            'precision': precision[1],\n",
    "            'recall': recall[1],\n",
    "            'f1_score': f1_score[1],\n",
    "            'count':len(y_labels[y_truth_label].values)\n",
    "        }\n",
    "\n",
    "        results_list.append(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_results = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results_melt = pd.melt(full_model_results, id_vars=['model','attribute'], value_vars=['precision','f1_score','recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below should be the Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"5\" halign=\"left\">value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>BERT</th>\n",
       "      <th>DeBERTa v3</th>\n",
       "      <th>GPT-3</th>\n",
       "      <th>RoBERTa</th>\n",
       "      <th>human</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th>attribute</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">f1_score</th>\n",
       "      <th>identity_attack</th>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>0.403226</td>\n",
       "      <td>0.343891</td>\n",
       "      <td>0.480211</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.686869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0.270904</td>\n",
       "      <td>0.258457</td>\n",
       "      <td>0.264572</td>\n",
       "      <td>0.265495</td>\n",
       "      <td>0.480370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profanity</th>\n",
       "      <td>0.788774</td>\n",
       "      <td>0.793558</td>\n",
       "      <td>0.827014</td>\n",
       "      <td>0.793558</td>\n",
       "      <td>0.882883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_toxicity</th>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxicity</th>\n",
       "      <td>0.344371</td>\n",
       "      <td>0.290749</td>\n",
       "      <td>0.070796</td>\n",
       "      <td>0.309795</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">precision</th>\n",
       "      <th>identity_attack</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.372093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.417582</td>\n",
       "      <td>0.365462</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.641509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0.270355</td>\n",
       "      <td>0.258108</td>\n",
       "      <td>0.266758</td>\n",
       "      <td>0.264957</td>\n",
       "      <td>0.412698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profanity</th>\n",
       "      <td>0.981618</td>\n",
       "      <td>0.974820</td>\n",
       "      <td>0.794989</td>\n",
       "      <td>0.974820</td>\n",
       "      <td>0.890909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_toxicity</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxicity</th>\n",
       "      <td>0.226744</td>\n",
       "      <td>0.191304</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.206061</td>\n",
       "      <td>0.575758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">recall</th>\n",
       "      <th>identity_attack</th>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>insult</th>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.292308</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.415385</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall</th>\n",
       "      <td>0.271454</td>\n",
       "      <td>0.258808</td>\n",
       "      <td>0.262421</td>\n",
       "      <td>0.266034</td>\n",
       "      <td>0.574586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profanity</th>\n",
       "      <td>0.659259</td>\n",
       "      <td>0.669136</td>\n",
       "      <td>0.861728</td>\n",
       "      <td>0.669136</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>severe_toxicity</th>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>threat</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxicity</th>\n",
       "      <td>0.715596</td>\n",
       "      <td>0.605505</td>\n",
       "      <td>0.036697</td>\n",
       "      <td>0.623853</td>\n",
       "      <td>0.904762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              value                                         \n",
       "model                          BERT DeBERTa v3     GPT-3   RoBERTa     human\n",
       "variable  attribute                                                         \n",
       "f1_score  identity_attack  0.085714   0.080000  0.160000  0.111111  0.500000\n",
       "          insult           0.403226   0.343891  0.480211  0.421875  0.686869\n",
       "          overall          0.270904   0.258457  0.264572  0.265495  0.480370\n",
       "          profanity        0.788774   0.793558  0.827014  0.793558  0.882883\n",
       "          severe_toxicity  0.074074   0.097561  0.388889  0.000000  0.375000\n",
       "          threat           0.000000   0.000000  0.117647  0.400000  0.666667\n",
       "          toxicity         0.344371   0.290749  0.070796  0.309795  0.703704\n",
       "precision identity_attack  1.000000   0.375000  0.750000  0.800000  0.372093\n",
       "          insult           0.423729   0.417582  0.365462  0.428571  0.641509\n",
       "          overall          0.270355   0.258108  0.266758  0.264957  0.412698\n",
       "          profanity        0.981618   0.974820  0.794989  0.974820  0.890909\n",
       "          severe_toxicity  0.333333   0.117647  0.583333  0.000000  0.272727\n",
       "          threat           0.000000   0.000000  0.071429  0.500000  0.500000\n",
       "          toxicity         0.226744   0.191304  1.000000  0.206061  0.575758\n",
       "recall    identity_attack  0.044776   0.044776  0.089552  0.059701  0.761905\n",
       "          insult           0.384615   0.292308  0.700000  0.415385  0.739130\n",
       "          overall          0.271454   0.258808  0.262421  0.266034  0.574586\n",
       "          profanity        0.659259   0.669136  0.861728  0.669136  0.875000\n",
       "          severe_toxicity  0.041667   0.083333  0.291667  0.000000  0.600000\n",
       "          threat           0.000000   0.000000  0.333333  0.333333  1.000000\n",
       "          toxicity         0.715596   0.605505  0.036697  0.623853  0.904762"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(\n",
    "    model_results_melt, \n",
    "         values=['value'],\n",
    "         index=['variable','attribute'],\n",
    "         columns='model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{llrrrrr}\\n &  & \\\\multicolumn{5}{r}{value} \\\\\\\\\\n & model & BERT & DeBERTa v3 & RoBERTa & human_1 & human_2 \\\\\\\\\\nvariable & attribute &  &  &  &  &  \\\\\\\\\\n\\\\multirow[c]{7}{*}{f1_score} & identity_attack & 0.085714 & 0.080000 & 0.111111 & 0.500000 & 0.413793 \\\\\\\\\\n & insult & 0.403226 & 0.343891 & 0.421875 & 0.686869 & 0.708861 \\\\\\\\\\n & overall & 0.270904 & 0.258457 & 0.265495 & 0.480370 & 0.336957 \\\\\\\\\\n & profanity & 0.788774 & 0.793558 & 0.793558 & 0.882883 & 0.882353 \\\\\\\\\\n & severe_toxicity & 0.074074 & 0.097561 & 0.000000 & 0.375000 & 0.000000 \\\\\\\\\\n & threat & 0.000000 & 0.000000 & 0.400000 & 0.666667 & 0.000000 \\\\\\\\\\n & toxicity & 0.344371 & 0.290749 & 0.309795 & 0.703704 & 0.285714 \\\\\\\\\\n\\\\multirow[c]{7}{*}{precision} & identity_attack & 1.000000 & 0.375000 & 0.800000 & 0.372093 & 0.750000 \\\\\\\\\\n & insult & 0.423729 & 0.417582 & 0.428571 & 0.641509 & 0.848485 \\\\\\\\\\n & overall & 0.270355 & 0.258108 & 0.264957 & 0.412698 & 0.489474 \\\\\\\\\\n & profanity & 0.981618 & 0.974820 & 0.974820 & 0.890909 & 0.978261 \\\\\\\\\\n & severe_toxicity & 0.333333 & 0.117647 & 0.000000 & 0.272727 & 0.000000 \\\\\\\\\\n & threat & 0.000000 & 0.000000 & 0.500000 & 0.500000 & 0.000000 \\\\\\\\\\n & toxicity & 0.226744 & 0.191304 & 0.206061 & 0.575758 & 1.000000 \\\\\\\\\\n\\\\multirow[c]{7}{*}{recall} & identity_attack & 0.044776 & 0.044776 & 0.059701 & 0.761905 & 0.285714 \\\\\\\\\\n & insult & 0.384615 & 0.292308 & 0.415385 & 0.739130 & 0.608696 \\\\\\\\\\n & overall & 0.271454 & 0.258808 & 0.266034 & 0.574586 & 0.256906 \\\\\\\\\\n & profanity & 0.659259 & 0.669136 & 0.669136 & 0.875000 & 0.803571 \\\\\\\\\\n & severe_toxicity & 0.041667 & 0.083333 & 0.000000 & 0.600000 & 0.000000 \\\\\\\\\\n & threat & 0.000000 & 0.000000 & 0.333333 & 1.000000 & 0.000000 \\\\\\\\\\n & toxicity & 0.715596 & 0.605505 & 0.623853 & 0.904762 & 0.166667 \\\\\\\\\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(\n",
    "    model_results_melt, \n",
    "         values=['value'],\n",
    "         index=['variable','attribute'],\n",
    "         columns='model'\n",
    ").style.to_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
